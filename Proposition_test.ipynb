{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9928f624-88fc-4749-8dc0-28e8d79d56a1",
   "metadata": {},
   "source": [
    "## Propositional variation with MFT Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c276eda6-642f-43c1-a47f-eab03f84109b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this cell of code you can comment out once you installed the following tools in your environment\n",
    "# pip install panda\n",
    "# pip install allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f04948bf-8ed6-4153-a6d4-4ca43e95e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "from allennlp_models import pretrained\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import csv\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\anaverageone\\htlt_env\\Advanced_NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b24d251-fcf7-4290-b055-362ade40f150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\ANAVER~1\\AppData\\Local\\Temp\\tmp0er_6lmj\\config.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\coref-spanbert.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\evaluate_rc-lerc.json as plain json\n",
      "lerc is not a registered model.\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\generation-bart.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\glove-sst.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\lm-masked-language-model.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\lm-next-token-lm-gpt2.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\mc-roberta-commonsenseqa.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\mc-roberta-piqa.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\mc-roberta-swag.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\nlvr2-vilbert-head.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\nlvr2-vilbert.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\pair-classification-adversarial-binary-gender-bias-mitigated-roberta-snli.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\pair-classification-binary-gender-bias-mitigated-roberta-snli.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\pair-classification-decomposable-attention-elmo.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\pair-classification-esim.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\pair-classification-roberta-mnli.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\pair-classification-roberta-rte.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\pair-classification-roberta-snli.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\rc-bidaf-elmo.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\rc-bidaf.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\rc-naqanet.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\rc-nmn.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\rc-transformer-qa.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\roberta-sst.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\semparse-nlvr.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\semparse-text-to-sql.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\semparse-wikitables.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\structured-prediction-biaffine-parser.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\structured-prediction-constituency-parser.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\structured-prediction-srl-bert.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\structured-prediction-srl.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\tagging-elmo-crf-tagger.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\tagging-fine-grained-crf-tagger.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\tagging-fine-grained-transformer-crf-tagger.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\ve-vilbert.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\vgqa-vilbert.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating D:\\ANACONDA\\Lib\\site-packages\\allennlp_models\\modelcards\\vqa-vilbert.json as plain json\n",
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\ANAVER~1\\AppData\\Local\\Temp\\tmpzz5qkk5s\\config.json as plain json\n"
     ]
    }
   ],
   "source": [
    "# Loading BERT_based and BiLSTM models from AllenNLP tool package\n",
    "Bert_based = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n",
    "BiLSTM = pretrained.load_predictor(\"structured-prediction-srl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "698a2c11-4a1e-42df-bdea-8fe20434f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create original data set in the format of lists\n",
    "# sentence samples are originally from en_ewt-up-train.conllu & en_ewt-up-test.conllu\n",
    "sentences = [\n",
    "    \"Along with an area on the page for those to join the mailing list.\", \n",
    "    \"I went with Natasha.\",\n",
    "    \"Deep tissue massage helps with pain in neck and shoulders\",\n",
    "    \"The setting feels like a Sushi bar in NYC; small, cozy, but with flair.\",\n",
    "    \"They have awesome service with a smile :)\"]\n",
    "\n",
    "gold = [\n",
    "   [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"O\", \"B-V\", \"O\", \"O\", \"B-ARG1\", \"O\"],\n",
    "    [\"B-ARG0\", \"B-V\", \"O\",\"B-ARG1\" \"O\"] ,\n",
    "    [\"O\", \"O\", \"B-ARG0\", \"B-V\", \"O\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\"] ,\n",
    "    [\"O\", \"B-ARG1\", \"B-V\", \"O\", \"O\", \"O\", \"B-ARG2\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"],\n",
    "    [\"B-ARG0\", \"B-V\", \"B-ARGM-ADJ\",\"B-ARG1\", \"O\", \"O\", \"B-ARGM-MNR\", \"O\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6201ffb9-8a4a-4fff-a750-361e17ea1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that saves challenge data as csv file \n",
    "def create_challenge_data(outfile, test_samples, test_gold):\n",
    "    with open(outfile, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "    # write headers\n",
    "        writer.writerow([\"Sentence\", \"Gold\"])\n",
    "    # write each sentence and its corresponding gold labels\n",
    "        for i in range(len(test_samples)):\n",
    "            writer.writerow([test_samples[i], test_gold[i]])\n",
    "            \n",
    "# a function that prints out the failure rate of model on corresponding challenge data set \n",
    "def get_Pred_results(outfile, predictor_name, test_samples):\n",
    "    with open(outfile, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "    # write headers\n",
    "        writer.writerow([\"Sentence\", \"Arguments\"])\n",
    "    # Loop through sentences and arguements\n",
    "        for sent in test_samples:\n",
    "            output = predictor_name.predict(sentence=sent)\n",
    "        # for sentences with more than one predicate\n",
    "            if len(output[\"verbs\"]) > 1:\n",
    "                arguments = output[\"verbs\"][1][\"tags\"]\n",
    "                print(arguments)\n",
    "                writer.writerow([sent, arguments])\n",
    "        # for sentences with one predicte \n",
    "            elif len(output[\"verbs\"]) == 1:\n",
    "                arguments = output[\"verbs\"][0][\"tags\"]\n",
    "                print(arguments)\n",
    "                writer.writerow([sent, arguments])\n",
    "        # for sentences without verbs\n",
    "            else:\n",
    "                writer.writerow([sent, \" \"])\n",
    "                print('NaN')\n",
    "\n",
    "# a function that iterate through each token and find matches(both span & lable count as correct)\n",
    "def calculate_failure_rate(model_name, test_name, gold_arg, model_arg):\n",
    "    matches_counter = 0\n",
    "    token_counter = 0\n",
    "    for i, sent_arg in enumerate(gold_arg):\n",
    "        gold_list = ast.literal_eval(sent_arg)\n",
    "        pred_list = ast.literal_eval(model_arg[i])\n",
    "        for i in range(len(gold_list)):\n",
    "            if gold_list[i] != pred_list[i]:\n",
    "                token_counter += 1\n",
    "            else:\n",
    "                token_counter += 1\n",
    "                matches_counter += 1\n",
    "    failure_rate = (token_counter - matches_counter) / token_counter\n",
    "    print(f'{model_name} model yeilds a {failure_rate} failure rate for {test_name} test!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8dba428-1fc4-4778-a2aa-f6a2f2733525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call \"create_challenge_data\" to save challenge data as csv file(s)\n",
    "create_challenge_data('data/proposition_file.csv', sentences, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "623a0f3c-bed3-4305-ab18-d3498e6c7553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARG0', 'O', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'O']\n",
      "['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'O']\n",
      "['B-ARG0', 'I-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1']\n",
      "['B-ARG1', 'I-ARG1', 'B-V', 'B-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'I-ARG2', 'O']\n",
      "['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'B-ARGM-MNR', 'I-ARGM-MNR', 'I-ARGM-MNR', 'O']\n",
      "\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ARG0', 'O', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'O']\n",
      "['B-ARG0', 'B-V', 'B-ARGM-COM', 'I-ARGM-COM', 'O']\n",
      "['B-ARG0', 'I-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1']\n",
      "['B-ARG0', 'I-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'O']\n",
      "['B-ARG0', 'B-V', 'B-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1', 'I-ARG1']\n"
     ]
    }
   ],
   "source": [
    "# call \"get_Pred_results\" to save model predictions as csv file(s)\n",
    "get_Pred_results('data/Bertbased_proposition.csv', Bert_based, sentences)\n",
    "print()\n",
    "get_Pred_results('data/BiLSTM_proposition.csv', BiLSTM, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb320a-7b13-439d-88e4-6dffedca0ba3",
   "metadata": {},
   "source": [
    "### Evaluation (failure rate) on challenge data (token level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb965603-8f73-43cb-87ae-29a3e0cff86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test data file and model predictions as pandas dataframe\n",
    "df_gold = pd.read_csv('data/proposition_file.csv', sep=',')\n",
    "df_bert = pd.read_csv('data/Bertbased_proposition.csv', sep=',')\n",
    "df_bilstm = pd.read_csv('data/BiLSTM_proposition.csv', sep=',')\n",
    "df_gold.fillna(0)\n",
    "df_bert.fillna(0)\n",
    "df_bilstm.fillna(0)\n",
    "# prepare argument labels for comparison \n",
    "bert_arg = df_bert['Arguments'].tolist()\n",
    "bilstm_arg = df_bilstm['Arguments'].tolist()\n",
    "gold_arg = df_gold['Gold'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d141d-3c54-4d59-8fbe-c9c02dd0537a",
   "metadata": {},
   "source": [
    "### Bert-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92c88f83-7992-4d70-847d-1cb94cac63b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertbased model yeilds a 0.6363636363636364 failure rate for Propositional construction test!\n"
     ]
    }
   ],
   "source": [
    "# call the caculation function to compute failure rate for each model\n",
    "calculate_failure_rate('Bertbased', 'Propositional construction', gold_arg, bert_arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec11f97-1858-4e63-95f7-bc64cfc20e51",
   "metadata": {},
   "source": [
    "### BiLSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad150b61-cd46-4662-b09d-6204debd0158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM model yeilds a 0.6545454545454545 failure rate for Propositional construction test!\n"
     ]
    }
   ],
   "source": [
    "calculate_failure_rate('BiLSTM', 'Propositional construction', gold_arg, bilstm_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dcc33b-a3d2-46d4-a4d9-c95357717e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70bc59-6f2d-493d-bd95-cce27e4a27ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15633ce-7e93-4e35-a337-f8388bb23d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
